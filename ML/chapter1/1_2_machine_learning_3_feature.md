**머신 러닝의 세 가지 종류**<br>

지도학습<br>  -> 레이블된 훈련 데이터에서 모델을 학습하여 본 적 없는 미래 데이터에 대해 예측을 만드는것

레이블된 데이터 -> 결과값을 알려주는 데이터<br>
직접 피드백<br>
출력 및 미래 예측<br>

레이블 : 머신 러닝에서 특정 샘플에 할당된 클래스를 레이블<br>
레이블/훈련데이터 -> 머신러닝 알고리즘 -> 예측모델 -> 예측
예) 스팸 이메일 <br>
레이블된 이메일 데이터셋에서 지도 학습 머신 러닝 알고리즘을 사용하여 모델을 훈련할 수 있다 이 데이터셋은 스팸 또는 스팸이 아닌 이메일로 정확하게 표시되어 있다 

 **분류: 클래스 예측**

지도학습의 하위 카테고리 과거의 관측을 기반으로 새로운 샘플의 범주형 클래스 레이블을 예측 클래스 레이블은 이산적이고 순서가 없어 샘플이 속한 그룹으로 이해할 수 있습니다 앞서 언급한 스팸이메일 감지는 전형적인 이진 분류 작업의 예이다 o x 중 하나로 구분<br>
두개이상의 클래스 레이블 가진 경우 지도 학습 알고리즘으로 학습한 예측 모델은 훈련 데이터셋에 있는 모든 클래스 레이블을 새로운 샘플에 할당할수 있다
음성클래스 / 양성클래스

 **회귀: 연속적인 출력 값 예측** <br>
범주형 -> 레이블을 샘플에 할당하는 것 예측변수와 반응변수 주어졌을때 두 변수간의 관계를 찾는다
~~~
수학점수 예측 
시험공부 투자한 시간 + 최종 점수

~~~
선형회귀 샘플과 직선사이 거리가 최소가 되는 직선을 그을수 있다

**비지도 학습**
레이블 및 타깃 없음 <br>
피드백 없음 <br>
데이터에서 숨겨진 구조 찾기<br>

**군집 서브그룹 찾기**<br>
그룹 정보를 의미 있는 서브그룹 또는 클러스터로 조직하는
탐색적 데이터 분석 기법

**차원 축소: 데이터 압축** 
고차원의 데이터를 다루어야하는 경우가 흔하다 
~~~
비지도 차원 축소는 잡음 데이터를 제거하기 위해 특성 전처리 단계에서 종종 적용된 방법1
~~~



**강화학습**<br>
결정과정 <br>
보상 시스템<br>
연속된 행동에서 학습<br>
환경의 현재 상태 정보는 보상신호를 포함하기 때문에 강화 학습을 지도 학습과 관련된 분야로 생각할 수 있다 보상함수로 얼마나 행동이 좋은지를 측정한 값이다 에이전트 환경과 상호 작용하여 보상이 최대화되는 일련의 행동을 강화학습으로 학습한다 양의 보상과 음의 보상과 연관된다 
 <br>
~~~
에이전트는 체스판의 상태에 따라 기물의 이동을 결정하낟 보상은 게임을 종료했을때 승리하거나 패배하는 것을 정의할 수 있다
~~~







